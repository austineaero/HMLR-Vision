{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c36e07f-6d55-4258-8eea-1d2a200d0cbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cf53500-e51e-45e1-9d01-3cd8ecd2cca2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import easyocr\n",
    "\n",
    "from src.data_loader import SingleImageDataset, VAL_TRANSFORM\n",
    "from src.unet_model import load_unet, infer_masks\n",
    "from src.geo_export import export_geopackage\n",
    "from src.mask_utils import hsv_red_mask, postprocess_boundary_mask\n",
    "\n",
    "# --- Load image and model ---\n",
    "img_path = \"data/stockton_1.png\"\n",
    "img = cv2.imread(img_path)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "orig_h, orig_w = img.shape[:2]\n",
    "\n",
    "dataset = SingleImageDataset(img_path, mask_path=None, transform=VAL_TRANSFORM)\n",
    "dataloader = DataLoader(dataset, batch_size=1)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = load_unet(\"checkpoints/unet_last.pt\", classes=3, in_channels=3, device=device)\n",
    "\n",
    "# --- Model predictions (raw, not post-processed) ---\n",
    "boundary_512, text_512 = infer_masks(model, dataloader, device)\n",
    "# Resize back to original size\n",
    "scale = lambda m: cv2.resize(m, (orig_w, orig_h), cv2.INTER_NEAREST)\n",
    "boundary_pred = scale(boundary_512)    # Model's boundary prediction (0/1 mask)\n",
    "text_pred     = scale(text_512)        # Model's text prediction (0/1 mask)\n",
    "\n",
    "# --- HSV masks (for red) ---\n",
    "red_hsv_mask = hsv_red_mask(img_rgb)    # Binary mask where HSV says \"red\"\n",
    "\n",
    "# --- Filtered masks: model AND HSV ---\n",
    "boundary_final = np.logical_and(boundary_pred, red_hsv_mask).astype(np.uint8)\n",
    "boundary_final = postprocess_boundary_mask(boundary_final, min_size=100)   # Remove small blobs\n",
    "text_final = np.logical_and(text_pred, red_hsv_mask).astype(np.uint8)\n",
    "\n",
    "# --- OCR only where model+HSV say it's text ---\n",
    "reader = easyocr.Reader(['en'], gpu=(device=='cuda'))\n",
    "img_with_ocr = img_rgb.copy()\n",
    "contours, _ = cv2.findContours(text_final, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "ocr_results = []\n",
    "for cnt in contours:\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    roi = img_rgb[y:y+h, x:x+w]\n",
    "    result = reader.readtext(roi)\n",
    "    text = result[0][1] if result else \"\"\n",
    "    # Visualise\n",
    "    cv2.rectangle(img_with_ocr, (x, y), (x+w, y+h), (0,0,255), 2)\n",
    "    cv2.putText(img_with_ocr, text, (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 1.1, (0,0,255), 2)\n",
    "    ocr_results.append((x, y, w, h, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba19c68e-b25d-4812-95f2-fab2b4213afa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- EXPORT GEO DATA ---\n",
    "# This saves the final boundary and text masks, with OCR labels, as polygons in output/segments.gpkg\n",
    "export_geopackage(\n",
    "    boundary_final,         # binary mask for boundary (filtered)\n",
    "    text_final,             # binary mask for text (filtered)\n",
    "    orig_w, orig_h,\n",
    "    \"output/segments.gpkg\",\n",
    "    text_labels=[t[-1] for t in ocr_results]   # list of OCR results for each text region\n",
    ")\n",
    "print(\"GeoPackage saved: output/segments.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c01ea8d-3006-497d-87e3-d032def1d996",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Visualise all intermediate results ---\n",
    "plt.figure(figsize=(18,12))\n",
    "\n",
    "plt.subplot(2,3,1); plt.title(\"Original Image\"); plt.imshow(img_rgb); plt.axis('off')\n",
    "\n",
    "plt.subplot(2,3,2); plt.title(\"Boundary: Model Prediction\"); plt.imshow(boundary_pred, cmap='gray'); plt.axis('off')\n",
    "\n",
    "plt.subplot(2,3,3); plt.title(\"HSV Red Mask\"); plt.imshow(red_hsv_mask, cmap='gray'); plt.axis('off')\n",
    "\n",
    "plt.subplot(2,3,4); plt.title(\"Boundary: Model AND HSV\"); plt.imshow(boundary_final, cmap='gray'); plt.axis('off')\n",
    "\n",
    "plt.subplot(2,3,5); plt.title(\"Text: Model Prediction\"); plt.imshow(text_pred, cmap='gray'); plt.axis('off')\n",
    "\n",
    "plt.subplot(2,3,6); plt.title(\"Text: Model AND HSV + OCR\"); plt.imshow(img_with_ocr); plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "abe9916c-88fd-4b7a-a000-8f77e8fc775f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_inference_export",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
